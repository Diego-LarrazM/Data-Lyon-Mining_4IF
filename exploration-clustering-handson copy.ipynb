{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Data Mining project: Discover and describe areas of interest<br> and events from geo-located data</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1: Import Dataset and Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Actual environment location may have moved due to redirects, links or junctions.\n",
      "  Requested location: \"h:\\IF4\\fouilleD\\projet\\dataMiningEnv\\Scripts\\python.exe\"\n",
      "  Actual location:    \"\\\\ps-home.insa-lyon.fr\\users\\home\\dlarrazmar\\IF4\\fouilleD\\projet\\dataMiningEnv\\Scripts\\python.exe\"\n"
     ]
    }
   ],
   "source": [
    "! python -m venv dataMiningEnv\n",
    "#Activate windows\n",
    "! dataMiningEnv\\Scripts\\activate.bat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.26.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (1.26.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==2.1.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas==2.1.1) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas==2.1.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas==2.1.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas==2.1.1) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas==2.1.1) (1.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn==1.5.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn==1.5.1) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn==1.5.1) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn==1.5.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn==1.5.1) (3.5.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy==1.12.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scipy==1.12.0) (1.26.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly==5.24.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly==5.24.1) (8.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly==5.24.1) (24.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib==3.8.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib==3.8.0) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib==3.8.0) (1.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn==0.13.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from seaborn==0.13.2) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from seaborn==0.13.2) (2.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from seaborn==0.13.2) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (6.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=1.2->seaborn==0.13.2) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=1.2->seaborn==0.13.2) (2024.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly-express==0.4.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (0.4.1)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly-express==0.4.1) (2.1.1)\n",
      "Requirement already satisfied: plotly>=4.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly-express==0.4.1) (5.24.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly-express==0.4.1) (0.14.4)\n",
      "Requirement already satisfied: scipy>=0.18 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly-express==0.4.1) (1.12.0)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly-express==0.4.1) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly-express==0.4.1) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.20.0->plotly-express==0.4.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.20.0->plotly-express==0.4.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.20.0->plotly-express==0.4.1) (2024.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly>=4.1.0->plotly-express==0.4.1) (8.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly>=4.1.0->plotly-express==0.4.1) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->plotly-express==0.4.1) (1.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: chart-studio==1.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (1.1.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from chart-studio==1.1.0) (5.24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from chart-studio==1.1.0) (2.32.3)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from chart-studio==1.1.0) (1.3.4)\n",
      "Requirement already satisfied: six in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from chart-studio==1.1.0) (1.17.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly->chart-studio==1.1.0) (8.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from plotly->chart-studio==1.1.0) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from requests->chart-studio==1.1.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from requests->chart-studio==1.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from requests->chart-studio==1.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from requests->chart-studio==1.1.0) (2024.12.14)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: streamlit==1.37.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (1.37.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (1.26.0)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (2.1.1)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (5.29.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (13.9.4)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (6.4.2)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from streamlit==1.37.1) (4.0.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from altair<6,>=4.0->streamlit==1.37.1) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from altair<6,>=4.0->streamlit==1.37.1) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from altair<6,>=4.0->streamlit==1.37.1) (1.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from click<9,>=7.0->streamlit==1.37.1) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.37.1) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas<3,>=1.3.0->streamlit==1.37.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas<3,>=1.3.0->streamlit==1.37.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas<3,>=1.3.0->streamlit==1.37.1) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.27->streamlit==1.37.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.27->streamlit==1.37.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.27->streamlit==1.37.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.27->streamlit==1.37.1) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from rich<14,>=10.14.0->streamlit==1.37.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from rich<14,>=10.14.0->streamlit==1.37.1) (2.19.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.37.1) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from jinja2->altair<6,>=4.0->streamlit==1.37.1) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.37.1) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.37.1) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.37.1) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.37.1) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.37.1) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit==1.37.1) (1.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mlxtend==0.23.3 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (0.23.3)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from mlxtend==0.23.3) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from mlxtend==0.23.3) (1.26.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from mlxtend==0.23.3) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from mlxtend==0.23.3) (1.5.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from mlxtend==0.23.3) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from mlxtend==0.23.3) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->mlxtend==0.23.3) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->mlxtend==0.23.3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->mlxtend==0.23.3) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->mlxtend==0.23.3) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->mlxtend==0.23.3) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->mlxtend==0.23.3) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->mlxtend==0.23.3) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->mlxtend==0.23.3) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->mlxtend==0.23.3) (6.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.24.2->mlxtend==0.23.3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.24.2->mlxtend==0.23.3) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn>=1.3.1->mlxtend==0.23.3) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.0.0->mlxtend==0.23.3) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend==0.23.3) (1.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.6)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# installation of required libraries and dependencies\n",
    "# numeric calculations\n",
    "! pip install numpy==1.26.0 \n",
    "# data frames \n",
    "! pip install pandas==2.1.1 \n",
    "# machine learning algorithms \n",
    "! pip install scikit-learn==1.5.1 \n",
    "! pip install scipy==1.12.0\n",
    "# plotting \n",
    "! pip install plotly==5.24.1 \n",
    "! pip install matplotlib==3.8.0 \n",
    "! pip install seaborn==0.13.2 \n",
    "! pip install plotly-express==0.4.1 \n",
    "! pip install chart-studio==1.1.0 \n",
    "# web app library \n",
    "! pip install streamlit==1.37.1 \n",
    "# association rules\n",
    "! pip install mlxtend==0.23.3\n",
    "# Language processing\n",
    "! pip install nltk\n",
    "! python -m nltk.downloader popular # popular functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import nltk\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlarrazmar\\AppData\\Local\\Temp\\ipykernel_11016\\3294269401.py:2: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_table(\"data/flickr_data2.csv\", sep=\",\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_upload_minute</th>\n",
       "      <th>date_upload_hour</th>\n",
       "      <th>date_upload_day</th>\n",
       "      <th>date_upload_month</th>\n",
       "      <th>date_upload_year</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4395181099</td>\n",
       "      <td>30624617@N03</td>\n",
       "      <td>45.754858</td>\n",
       "      <td>4.821710</td>\n",
       "      <td>chair,lyon,rhône,chaise,rhônealpes</td>\n",
       "      <td>Chaises avec vue</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4394748717</td>\n",
       "      <td>35853470@N00</td>\n",
       "      <td>45.753270</td>\n",
       "      <td>4.862953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394694699</td>\n",
       "      <td>11817998@N05</td>\n",
       "      <td>45.760655</td>\n",
       "      <td>4.846564</td>\n",
       "      <td>365,iphone</td>\n",
       "      <td>59/365 - R46 V103 B163</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4394803790</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-29 Toiou Avott Lyon</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4394803554</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>lyon,nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-28 Toiou Avott Lyon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          user        lat      long  \\\n",
       "0  4395181099  30624617@N03  45.754858  4.821710   \n",
       "1  4394748717  35853470@N00  45.753270  4.862953   \n",
       "2  4394694699  11817998@N05  45.760655  4.846564   \n",
       "3  4394803790  11545749@N06  45.784000  4.874072   \n",
       "4  4394803554  11545749@N06  45.784000  4.874072   \n",
       "\n",
       "                                                tags  \\\n",
       "0                 chair,lyon,rhône,chaise,rhônealpes   \n",
       "1                                                NaN   \n",
       "2                                         365,iphone   \n",
       "3       nin,nineinchnails,gift,screening,toiou,avott   \n",
       "4  lyon,nin,nineinchnails,gift,screening,toiou,avott   \n",
       "\n",
       "                         title   date_taken_minute   date_taken_hour  \\\n",
       "0             Chaises avec vue                11.0                15   \n",
       "1                          NaN                51.0                17   \n",
       "2       59/365 - R46 V103 B163                29.0                17   \n",
       "3  2010-01-29 Toiou Avott Lyon                15.0                20   \n",
       "4  2010-01-28 Toiou Avott Lyon                10.0                20   \n",
       "\n",
       "    date_taken_day   date_taken_month   date_taken_year  date_upload_minute  \\\n",
       "0               28                  2              2010                  23   \n",
       "1               28                  2              2010                  52   \n",
       "2               28                  2              2010                  33   \n",
       "3               28                  1              2010                  38   \n",
       "4               28                  1              2010                  38   \n",
       "\n",
       "   date_upload_hour   date_upload_day   date_upload_month   date_upload_year  \\\n",
       "0                20              28.0                   2             2010.0   \n",
       "1                17              28.0                   2             2010.0   \n",
       "2                17              28.0                   2             2010.0   \n",
       "3                12              28.0                   2             2010.0   \n",
       "4                12              28.0                   2             2010.0   \n",
       "\n",
       "   Unnamed: 16  Unnamed: 17  Unnamed: 18  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from table file where entries are separated with a space\n",
    "data = pd.read_table(\"data/flickr_data2.csv\", sep=\",\" )\n",
    "# show first 5 rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_upload_minute</th>\n",
       "      <th>date_upload_hour</th>\n",
       "      <th>date_upload_day</th>\n",
       "      <th>date_upload_month</th>\n",
       "      <th>date_upload_year</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4395181099</td>\n",
       "      <td>30624617@N03</td>\n",
       "      <td>45.754858</td>\n",
       "      <td>4.821710</td>\n",
       "      <td>chair,lyon,rhône,chaise,rhônealpes</td>\n",
       "      <td>Chaises avec vue</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4394748717</td>\n",
       "      <td>35853470@N00</td>\n",
       "      <td>45.753270</td>\n",
       "      <td>4.862953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394694699</td>\n",
       "      <td>11817998@N05</td>\n",
       "      <td>45.760655</td>\n",
       "      <td>4.846564</td>\n",
       "      <td>365,iphone</td>\n",
       "      <td>59/365 - R46 V103 B163</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4394803790</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-29 Toiou Avott Lyon</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4394803554</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>lyon,nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-28 Toiou Avott Lyon</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4394566432</td>\n",
       "      <td>16197488@N06</td>\n",
       "      <td>45.755940</td>\n",
       "      <td>4.833158</td>\n",
       "      <td>poste,lyon,streetphotography,rue,gens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4393799139</td>\n",
       "      <td>16197488@N06</td>\n",
       "      <td>45.754289</td>\n",
       "      <td>4.832257</td>\n",
       "      <td>lyon,streetphotography,rue,gens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4394565970</td>\n",
       "      <td>16197488@N06</td>\n",
       "      <td>45.774662</td>\n",
       "      <td>4.834005</td>\n",
       "      <td>lyon,streetphotography,rue,montblanc,gens,mont...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4392370105</td>\n",
       "      <td>47924539@N05</td>\n",
       "      <td>45.762328</td>\n",
       "      <td>4.827547</td>\n",
       "      <td>france,lyon,lesphotosdevoyage</td>\n",
       "      <td>Courette Lyonnaise</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4392367159</td>\n",
       "      <td>47924539@N05</td>\n",
       "      <td>45.762059</td>\n",
       "      <td>4.822654</td>\n",
       "      <td>france,lyon,fourvière,lesphotosdevoyage</td>\n",
       "      <td>Fourvière</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          user        lat      long  \\\n",
       "0  4395181099  30624617@N03  45.754858  4.821710   \n",
       "1  4394748717  35853470@N00  45.753270  4.862953   \n",
       "2  4394694699  11817998@N05  45.760655  4.846564   \n",
       "3  4394803790  11545749@N06  45.784000  4.874072   \n",
       "4  4394803554  11545749@N06  45.784000  4.874072   \n",
       "5  4394566432  16197488@N06  45.755940  4.833158   \n",
       "6  4393799139  16197488@N06  45.754289  4.832257   \n",
       "7  4394565970  16197488@N06  45.774662  4.834005   \n",
       "8  4392370105  47924539@N05  45.762328  4.827547   \n",
       "9  4392367159  47924539@N05  45.762059  4.822654   \n",
       "\n",
       "                                                tags  \\\n",
       "0                 chair,lyon,rhône,chaise,rhônealpes   \n",
       "1                                                NaN   \n",
       "2                                         365,iphone   \n",
       "3       nin,nineinchnails,gift,screening,toiou,avott   \n",
       "4  lyon,nin,nineinchnails,gift,screening,toiou,avott   \n",
       "5              poste,lyon,streetphotography,rue,gens   \n",
       "6                    lyon,streetphotography,rue,gens   \n",
       "7  lyon,streetphotography,rue,montblanc,gens,mont...   \n",
       "8                      france,lyon,lesphotosdevoyage   \n",
       "9            france,lyon,fourvière,lesphotosdevoyage   \n",
       "\n",
       "                         title  date_taken_minute  date_taken_hour  \\\n",
       "0             Chaises avec vue                 11               15   \n",
       "1                          NaN                 51               17   \n",
       "2       59/365 - R46 V103 B163                 29               17   \n",
       "3  2010-01-29 Toiou Avott Lyon                 15               20   \n",
       "4  2010-01-28 Toiou Avott Lyon                 10               20   \n",
       "5                          NaN                 57               12   \n",
       "6                          NaN                  8               11   \n",
       "7                          NaN                 23               10   \n",
       "8           Courette Lyonnaise                 29               12   \n",
       "9                    Fourvière                 28               12   \n",
       "\n",
       "   date_taken_day  date_taken_month  date_taken_year  date_upload_minute  \\\n",
       "0              28                 2             2010                  23   \n",
       "1              28                 2             2010                  52   \n",
       "2              28                 2             2010                  33   \n",
       "3              28                 1             2010                  38   \n",
       "4              28                 1             2010                  38   \n",
       "5              27                 2             2010                   1   \n",
       "6              27                 2             2010                   1   \n",
       "7              27                 2             2010                   0   \n",
       "8              27                 2             2010                  29   \n",
       "9              27                 2             2010                  28   \n",
       "\n",
       "   date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \\\n",
       "0                20               28                  2              2010   \n",
       "1                17               28                  2              2010   \n",
       "2                17               28                  2              2010   \n",
       "3                12               28                  2              2010   \n",
       "4                12               28                  2              2010   \n",
       "5                10               28                  2              2010   \n",
       "6                10               28                  2              2010   \n",
       "7                10               28                  2              2010   \n",
       "8                21               27                  2              2010   \n",
       "9                21               27                  2              2010   \n",
       "\n",
       "   Unnamed: 16  Unnamed: 17  Unnamed: 18  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  \n",
       "5          NaN          NaN          NaN  \n",
       "6          NaN          NaN          NaN  \n",
       "7          NaN          NaN          NaN  \n",
       "8          NaN          NaN          NaN  \n",
       "9          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les données avec `low_memory=False` pour éviter les avertissements\n",
    "data = pd.read_csv(\"data/flickr_data2.csv\", sep=\",\", low_memory=False)\n",
    "\n",
    "# Supprimer les espaces supplémentaires dans les noms des colonnes\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Convertir les colonnes contenant des types mixtes (object) en numériques\n",
    "# Liste des colonnes de type temps\n",
    "time_columns = [\n",
    "    'date_taken_minute', 'date_taken_hour', 'date_taken_day',\n",
    "    'date_taken_month', 'date_taken_year',\n",
    "    'date_upload_minute', 'date_upload_hour', 'date_upload_day',\n",
    "    'date_upload_month', 'date_upload_year'\n",
    "]\n",
    "\n",
    "# Convertir chaque colonne en int64\n",
    "for col in time_columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce').fillna(0).astype('int64')\n",
    "\n",
    "\n",
    "data.head(10)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2: Exploratory Data Analysis (Cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conclusion(pre_data, parsed_data):\n",
    "    l = len(pre_data)-len(parsed_data)\n",
    "    print(f\"<Lines parsed: {l} - {round(100*l/len(data),3)}% of original data>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Lines parsed: 252143 - 60.0% of original data>\n"
     ]
    }
   ],
   "source": [
    "# Save parsed lines\n",
    "data[data['id'].duplicated(keep='first')].sort_values(\"id\").to_csv(\"data/parsed_lines/duplicatedId.csv\", index = False)\n",
    "\n",
    "# Parse\n",
    "unduplicated_id_data = data[~data['id'].duplicated(keep='first')]\n",
    "parse_conclusion(data, unduplicated_id_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupted Data and Shifted columns due to \";\" in title\n",
    "Examples:\n",
    "- https://flickr.com/photos/29713277@N02/6674970791\n",
    "- https://flickr.com/photos/53987060@N02/33105832478\n",
    "\n",
    "The first one clearly shows that if the title contains \";\", the data inside of the csv is shuffled.<br>\n",
    "The second example has a sneaky \";\" within the smily face at the end of the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Lines parsed: 47 - 0.011% of original data>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlarrazmar\\AppData\\Local\\Temp\\ipykernel_11016\\3587839137.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uncorrupted_data.drop(columns=[\"Unnamed: 16\", \"Unnamed: 17\", \"Unnamed: 18\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Save parsed lines\n",
    "corrupted_data = unduplicated_id_data[unduplicated_id_data[\"Unnamed: 16\"].notnull() | unduplicated_id_data[\"Unnamed: 17\"].notnull() | unduplicated_id_data[\"Unnamed: 18\"].notnull()]\n",
    "corrupted_data.to_csv(\"data/parsed_lines/corrupted_data.csv\", index = False)\n",
    "\n",
    "# Parse\n",
    "uncorrupted_data = unduplicated_id_data[~(unduplicated_id_data[\"Unnamed: 16\"].notnull() | unduplicated_id_data[\"Unnamed: 17\"].notnull() | unduplicated_id_data[\"Unnamed: 18\"].notnull())]\n",
    "\n",
    "# Drop colums 16, 17, 18\n",
    "uncorrupted_data = uncorrupted_data.drop(columns=[\"Unnamed: 16\", \"Unnamed: 17\", \"Unnamed: 18\"])\n",
    "uncorrupted_data.head(10)\n",
    "\n",
    "parse_conclusion(unduplicated_id_data, uncorrupted_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same user, space and approximated time => many captures taken on site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parsed lines\n",
    "\n",
    "# Parse\n",
    "display(uncorrupted_data[uncorrupted_data[['user', 'lat', 'long', 'date_taken_day', 'date_taken_month', 'date_taken_year']].duplicated(keep='first')].sort_values(\"id\"))\n",
    "#.to_csv(\"data/parsed_lines/duplicatedId.csv\", index = False)\n",
    "#parsed_data = data[~data['id'].duplicated(keep='first')]\n",
    "#print(f\"Size of Data pre-parsed: {len(parsed_data)} - Size of Data {len(parsed_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "user                       0\n",
       "lat                        0\n",
       "long                       0\n",
       "tags                       0\n",
       "title                      0\n",
       "date_taken_minute          1\n",
       "date_taken_hour            0\n",
       "date_taken_day             0\n",
       "date_taken_month           0\n",
       "date_taken_year            0\n",
       "date_upload_minute         0\n",
       "date_upload_hour           0\n",
       "date_upload_day            2\n",
       "date_upload_month          0\n",
       "date_upload_year           1\n",
       "Unnamed: 16           420098\n",
       "Unnamed: 17           420240\n",
       "Unnamed: 18           420238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 2: using isna() \n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see that there is no missing values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_upload_minute</th>\n",
       "      <th>date_upload_hour</th>\n",
       "      <th>date_upload_day</th>\n",
       "      <th>date_upload_month</th>\n",
       "      <th>date_upload_year</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4395181099</td>\n",
       "      <td>30624617@N03</td>\n",
       "      <td>45.754858</td>\n",
       "      <td>4.821710</td>\n",
       "      <td>chair,lyon,rhône,chaise,rhônealpes</td>\n",
       "      <td>Chaises avec vue</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4394748717</td>\n",
       "      <td>35853470@N00</td>\n",
       "      <td>45.753270</td>\n",
       "      <td>4.862953</td>\n",
       "      <td></td>\n",
       "      <td>Untitled</td>\n",
       "      <td>51.0</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394694699</td>\n",
       "      <td>11817998@N05</td>\n",
       "      <td>45.760655</td>\n",
       "      <td>4.846564</td>\n",
       "      <td>365,iphone</td>\n",
       "      <td>59/365 - R46 V103 B163</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4394803790</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-29 Toiou Avott Lyon</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4394803554</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>lyon,nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-28 Toiou Avott Lyon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420235</th>\n",
       "      <td>44402328654</td>\n",
       "      <td>90493526@N00</td>\n",
       "      <td>45.758316</td>\n",
       "      <td>4.825197</td>\n",
       "      <td>europe,france,lyon,croixrousse,streetart,wheat...</td>\n",
       "      <td>Pasted paper by Big Ben [Lyon, France]</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420236</th>\n",
       "      <td>44210748275</td>\n",
       "      <td>144146684@N04</td>\n",
       "      <td>45.762635</td>\n",
       "      <td>4.837299</td>\n",
       "      <td></td>\n",
       "      <td>white blood</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420237</th>\n",
       "      <td>45122361361</td>\n",
       "      <td>95450872@N03</td>\n",
       "      <td>45.763657</td>\n",
       "      <td>4.836012</td>\n",
       "      <td>auvergnerhônealpes,rhône,lyonnais,valléedurhôn...</td>\n",
       "      <td>Lyon - Porte Passage de l'Argue</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420238</th>\n",
       "      <td>45073351222</td>\n",
       "      <td>95450872@N03</td>\n",
       "      <td>45.763657</td>\n",
       "      <td>4.836012</td>\n",
       "      <td>auvergnerhônealpes,rhône,lyonnais,valléedurhôn...</td>\n",
       "      <td>Lyon - Passage de l'Argue</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420239</th>\n",
       "      <td>45122093111</td>\n",
       "      <td>61949122@N06</td>\n",
       "      <td>45.758181</td>\n",
       "      <td>4.831967</td>\n",
       "      <td>ngc,lyon,paysage,landscape,ville,urbain,town,tour</td>\n",
       "      <td>Une tour peut en cacher une autre</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420240 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           user        lat      long  \\\n",
       "0        4395181099   30624617@N03  45.754858  4.821710   \n",
       "1        4394748717   35853470@N00  45.753270  4.862953   \n",
       "2        4394694699   11817998@N05  45.760655  4.846564   \n",
       "3        4394803790   11545749@N06  45.784000  4.874072   \n",
       "4        4394803554   11545749@N06  45.784000  4.874072   \n",
       "...             ...            ...        ...       ...   \n",
       "420235  44402328654   90493526@N00  45.758316  4.825197   \n",
       "420236  44210748275  144146684@N04  45.762635  4.837299   \n",
       "420237  45122361361   95450872@N03  45.763657  4.836012   \n",
       "420238  45073351222   95450872@N03  45.763657  4.836012   \n",
       "420239  45122093111   61949122@N06  45.758181  4.831967   \n",
       "\n",
       "                                                     tags  \\\n",
       "0                      chair,lyon,rhône,chaise,rhônealpes   \n",
       "1                                                           \n",
       "2                                              365,iphone   \n",
       "3            nin,nineinchnails,gift,screening,toiou,avott   \n",
       "4       lyon,nin,nineinchnails,gift,screening,toiou,avott   \n",
       "...                                                   ...   \n",
       "420235  europe,france,lyon,croixrousse,streetart,wheat...   \n",
       "420236                                                      \n",
       "420237  auvergnerhônealpes,rhône,lyonnais,valléedurhôn...   \n",
       "420238  auvergnerhônealpes,rhône,lyonnais,valléedurhôn...   \n",
       "420239  ngc,lyon,paysage,landscape,ville,urbain,town,tour   \n",
       "\n",
       "                                         title  date_taken_minute  \\\n",
       "0                             Chaises avec vue               11.0   \n",
       "1                                     Untitled               51.0   \n",
       "2                       59/365 - R46 V103 B163               29.0   \n",
       "3                  2010-01-29 Toiou Avott Lyon               15.0   \n",
       "4                  2010-01-28 Toiou Avott Lyon               10.0   \n",
       "...                                        ...                ...   \n",
       "420235  Pasted paper by Big Ben [Lyon, France]               18.0   \n",
       "420236                             white blood               36.0   \n",
       "420237         Lyon - Porte Passage de l'Argue               48.0   \n",
       "420238               Lyon - Passage de l'Argue               48.0   \n",
       "420239       Une tour peut en cacher une autre               15.0   \n",
       "\n",
       "        date_taken_hour  date_taken_day  date_taken_month  date_taken_year  \\\n",
       "0                    15              28                 2             2010   \n",
       "1                    17              28                 2             2010   \n",
       "2                    17              28                 2             2010   \n",
       "3                    20              28                 1             2010   \n",
       "4                    20              28                 1             2010   \n",
       "...                 ...             ...               ...              ...   \n",
       "420235               17              30                 9             2018   \n",
       "420236               16               5                10             2018   \n",
       "420237               19              27                 9             2018   \n",
       "420238               19              27                 9             2018   \n",
       "420239               14              28                 9             2018   \n",
       "\n",
       "        date_upload_minute  date_upload_hour  date_upload_day  \\\n",
       "0                       23                20             28.0   \n",
       "1                       52                17             28.0   \n",
       "2                       33                17             28.0   \n",
       "3                       38                12             28.0   \n",
       "4                       38                12             28.0   \n",
       "...                    ...               ...              ...   \n",
       "420235                  11                23              5.0   \n",
       "420236                  41                22              5.0   \n",
       "420237                  40                22              5.0   \n",
       "420238                  29                22              5.0   \n",
       "420239                  21                22              5.0   \n",
       "\n",
       "        date_upload_month  date_upload_year  Unnamed: 16  Unnamed: 17  \\\n",
       "0                       2            2010.0          NaN          NaN   \n",
       "1                       2            2010.0          NaN          NaN   \n",
       "2                       2            2010.0          NaN          NaN   \n",
       "3                       2            2010.0          NaN          NaN   \n",
       "4                       2            2010.0          NaN          NaN   \n",
       "...                   ...               ...          ...          ...   \n",
       "420235                 10            2018.0          NaN          NaN   \n",
       "420236                 10            2018.0          NaN          NaN   \n",
       "420237                 10            2018.0          NaN          NaN   \n",
       "420238                 10            2018.0          NaN          NaN   \n",
       "420239                 10            2018.0          NaN          NaN   \n",
       "\n",
       "        Unnamed: 18  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "...             ...  \n",
       "420235          NaN  \n",
       "420236          NaN  \n",
       "420237          NaN  \n",
       "420238          NaN  \n",
       "420239          NaN  \n",
       "\n",
       "[420240 rows x 19 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 3: get the rwos with missing values\n",
    "data[data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return DataFrame is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **remove** the rows with missing values, you can use the [`dropna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) method. Check the parameters for more details.\n",
    "\n",
    "*Tip*: keep a track of the number of rows in the initial DataFrame and during and after the cleaning:\n",
    "```\n",
    "print(f\"Before: {len(df)}\")\n",
    "df_cleaned = df.dropna()\n",
    "print(f\"After: {len(df_cleaned)}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 420240\n",
      "After removing missing values: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial: {len(data)}\")\n",
    "data_cleaned = data.dropna()\n",
    "print(f\"After removing missing values: {len(data_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"duplicates\"></a>\n",
    "### Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check duplicated values, you can use the [`duplicated()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html) method. You can specify the paramater `keep` (`'first'`, `'last'`, `False`) to determine which duplicates (if any) to be maked as `True` in the resulting boolean Series indicating duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: bool)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the duplicates\n",
    "data_cleaned.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# check the duplicates of the class column and keep the last occurence\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data_cleaned[\u001b[39m'\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mduplicated(keep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "# check the duplicates of the class column and keep the last occurence\n",
    "data_cleaned['class'].duplicated(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another option using subset parameter\n",
    "data_cleaned.duplicated(subset=['class'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of duplicates\n",
    "data_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is one case of duplicates. Let's check the corresponding rows. We set the parameter `keep=False` to display all rows and not just the second occurence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned[data_cleaned.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep these rows or we can drop them (or any of them) using [`drop_duplicates`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html). Let's keep the first occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "data_cleaned = data_cleaned.drop_duplicates(keep='first')\n",
    "# show the stats\n",
    "print(f\"Initial: {len(data)}\")\n",
    "print(f\"After removing duplicates: {len(data_cleaned)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned DataFrame to `data/processed/data_cleaned.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "data_cleaned.to_csv('../data/processed/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='desc-stats'></a>\n",
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the statistical summary of the dataframe, we can use [`describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html). For different columns, it displays the count, the average value, the standard deviation, the min and max values, percentiles. \n",
    "By default, in mixed data types DataFrames, it displays the values for quantative data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarised statistics\n",
    "data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarised statistics with object data\n",
    "data_cleaned.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the range of values of the quantative attributes, we can see that their scales are comparable. So there is no need to scale them for futher use in algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the number of values for `class` column, we can use [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_cleaned['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Select the samples with the largest `sepal length`. Which type of iris flower it belongs to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "data_cleaned[data_cleaned[\"sepal length\"] == data_cleaned[\"sepal length\"].max()][\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data-vis'></a>\n",
    "### Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Pairplot](#pairplot)\n",
    "* [Correlation analysis](#correlation)\n",
    "* [Class-wise boxplot](#boxplot)\n",
    "* [Scatter plot with PCA](#pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pairplot'></a>\n",
    "#### Pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS:**\n",
    "\n",
    "- Let's start by plotting a pairplot using [`seaborn.paiplot()`](https://seaborn.pydata.org/generated/seaborn.pairplot.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# select columns to plot\n",
    "cols = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "# Plot the pairplot\n",
    "sns.pairplot(data_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, we can observe the following:\n",
    "* there is a strong positive linear relationship between `petal width` and `petal length`\n",
    "* we can observe two distinct groups, see `sepal length` vs. `petal length` for example or `petal length` vs. `petal width`. This can already give us an initial idea about a potential number of clusters and which features may influence more the separation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use of the `class` column to have a look on the data through the class labels. We will assign colors based on the value of `class`. To do so, we will assign the value to `hue` parameter. Mind that by default, the diagonal elements will disply a layered kernel density estimate (KDE). To change that, you can assign value to the `diag_kind` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pairplot\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "# pair plot\n",
    "g = sns.pairplot(data=data_cleaned[cols], hue='class', diag_kind='hist')\n",
    "# add a title to the figure\n",
    "g.figure.suptitle('Pairplot', y=1.04)\n",
    "# Remove the default legend\n",
    "g._legend.remove() \n",
    "# Add new legend\n",
    "g.add_legend(loc='upper right')\n",
    "# Adjust the layout to prevent title overlap\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using colors, we can see that a groups that stands apart corresponds to `Iris-setosa`. We can also observe that some values of `Iris-versicolor` and `Iris-virginica` are similar. This implied that a separation of the entries of these two classes might be difficult.\n",
    "\n",
    "**Note**: in this use case, there are true class labels which is not usually the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='correlation'></a>\n",
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**\n",
    "\n",
    "* Plot the correlation matrix and comment on the result.\n",
    "\n",
    "*Hint*: to calculate correlations, use the [`corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) method of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "# ANSWER\n",
    "corr = data_cleaned[features].corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENT: TO COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise this correlation matrix using a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "        corr,\n",
    "        annot=True,  # Show correlation values\n",
    "        cmap='coolwarm',  # Color scheme: red for positive, blue for negative\n",
    "        vmin=-1, vmax=1,  # Fix scale between -1 and 1\n",
    "        center=0,  # Center colormap at 0\n",
    "        fmt='.2f'  # Format correlation values to 2 decimal places\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boxplot'></a>\n",
    "#### Class-wise Boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display boxplots of each feature using [`seaborn.boxplot()`](https://seaborn.pydata.org/generated/seaborn.boxplot.html#seaborn.boxplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 1, figsize=(8, 16))\n",
    "fig.suptitle('Iris Features Distribution by Class')\n",
    "\n",
    "for ax, feature in zip(axes, features):\n",
    "    sns.boxplot(data=data_cleaned, x='class', y=feature, ax=ax, hue='class')\n",
    "    ax.set_title(feature)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:**\n",
    "\n",
    "* Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENT: TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pca'></a>\n",
    "#### Scatter Plot with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are four attributes that make it hard to visualise the whole dataset in one plot, we may want to use [*Principal Component Analysis* (PCA)](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# principal compomemt analysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# create PCA model with 2 components\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# apply PCA to numerical data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pca_result \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mfit_transform(data_cleaned[features])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "# create PCA model with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "# apply PCA to numerical data\n",
    "pca_result = pca.fit_transform(data_cleaned[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Create a DataFrame `pca_df` containing the result of PCA. This DataFrame should contain 2 columns: `PC1` and `PC2`\n",
    "* Create a new DataFrame `data_cleaned_pca` by contactenating `data_cleaned` and `pca_df`. Mind that the index of `data_cleaned` has been modified during the cleaning step. Reset the index before concatenation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned= data_cleaned.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "data_cleaned = data_cleaned.drop([\"index\"], axis= 1)\n",
    "pca_df = pd.DataFrame(pca_result, columns=[\"PC1\", \"PC2\"])\n",
    "data_cleaned_pca = data_cleaned.join(pca_df)\n",
    "print(data_cleaned_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install --upgrade pip\n",
    "! pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create interactive plots\n",
    "import plotly.express as px "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive scatter plot\n",
    "fig = px.scatter(\n",
    "        data_cleaned_pca,\n",
    "        x='PC1',\n",
    "        y='PC2',\n",
    "        color='class',\n",
    "        title='PCA visualization of all flowers'\n",
    ")\n",
    "# Add variance explained\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "fig.update_layout(\n",
    "        xaxis_title=f\"PC1 ({var_explained[0]:.1%} variance explained)\",\n",
    "        yaxis_title=f\"PC2 ({var_explained[1]:.1%} variance explained)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the contributions of each feature to principal components, let's see the loadings. Loadings are given by `eigenvectors * sqrt(explained variance)` (Eigenvectors are unit-scaled loadings. They show direction of maximum variance). Basically, loadings are the correlations between variables and components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric calculations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Calculate PCA `loadings`\n",
    "* Create a DataFrame for them. Display this DataFrame\n",
    "* Comment on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "loadings = pca.components_.T*np.sqrt(pca.explained_variance_)\n",
    "\n",
    "loadings_df = pd.DataFrame(loadings, index=features, columns=[\"PC1\", \"PC2\"])\n",
    "print(loadings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENT: TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #3: Prepare Data for Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create clusters without the use of `class` attribute. So let's drop this column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Create a DataFrame `df_clustering` by droping the column `class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "df_clustering = data_cleaned.drop(columns=[\"class\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though in our case the attributes have comparable scales, let's apply a [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Recall, that for a given value `x`, a standard score is given by $z = \\frac{x - mean(\\mathbf{x})}{std(\\mathbf{x})}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_clustering)\n",
    "# show\n",
    "print(scaled_data)\n",
    "# create a DataFrame\n",
    "scaled_data_df = pd.DataFrame(data=scaled_data, columns=df_clustering.columns)\n",
    "scaled_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #4: Apply k-means Clustering and Find the Optimal Number of Clusters using Elbow Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply **k-means clustering**, we are going to use [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). \n",
    "\n",
    "Mind that this algorithm requires a number of clusters as a parameter `k`. Let's first try `k=3` and then find the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of clusters \n",
    "k = 3\n",
    "# create a model\n",
    "kmeans = KMeans(n_clusters=k, init='k-means++')\n",
    "# fit scaled data\n",
    "kmeans.fit(scaled_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the associated labels using `labels_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associated cluster labels\n",
    "labels = kmeans.labels_\n",
    "print(f\"k-means labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the sum of squared distances of samples to their closest cluster center, use `inertia_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of squared distances\n",
    "inertia = kmeans.inertia_\n",
    "print(f\"Sum of squared distances: {inertia}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value can be used for finding the optimal number of clusters using the *Elbow method*. To do that let's vary the number of clusters `k`, apply k-means algorithm and store the corresponding intertia values. Then, let's plot the result and determine the best `k`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Find the optimal `k` using Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "ks_df = pd.DataFrame(columns=[\"k\", \"WCSS\"])\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++')\n",
    "    kmeans.fit(scaled_data_df)\n",
    "    new_row = pd.DataFrame({\"k\": [k], \"WCSS\": [kmeans.inertia_]})\n",
    "    ks_df = pd.concat([ks_df, new_row], ignore_index=True)\n",
    "\n",
    "plt.axis([1, 10, 0, 600])\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.plot(ks_df[\"k\"], ks_df[\"WCSS\"], \"-xb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENT: TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Add a column `cluster kmeans` to the `data_cleaned` DataFrame containing the labels of k-means clustering for `k=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "data_cleaned_cluster = data_cleaned.join(pd.DataFrame({\"cluster kmeans\": labels}))\n",
    "print(data_cleaned_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #5: Cluster Evaluation using Silhouette Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the quality of the clustering, we can use **Silhouette Coefficient**. The Silhouette Coefficient for a sample is given by $(b - a) / max(a, b)$ where `b` is the distance between a sample and the nearest cluster that the sample is not a part of, and `a` is the mean intra-cluster distance (i.e. the mean distance between a sample and all other samples in the same cluster). \n",
    "\n",
    "The silhouette score ranges from -1 to 1 and indicates how well each data point fits within its assigned cluster:\n",
    "\n",
    "* Score near +1 means:\n",
    "    - The data point is far from neighboring clusters\n",
    "    - The point is well-matched to its cluster\n",
    "    - Indicates very distinct, well-separated clustering\n",
    "* Score near 0 means:\n",
    "    - The data point is close to the decision boundary between clusters\n",
    "    - The point could potentially belong to either cluster\n",
    "    - Suggests overlapping or not well-defined clusters\n",
    "* Score near -1 means:\n",
    "    - The data point might be assigned to the wrong cluster\n",
    "    - The point is closer to points in another cluster than its own\n",
    "    - Indicates poor clustering or potential misassignments\n",
    "\n",
    "We can use [`sklearn.metrics.silhouette_score`](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.silhouette_score.html) and [`sklearn.metrics.silhouette_samples`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_samples.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silhouette scores\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* For k-means clustering with `k=3`, calculate Silhouette score for each data point, for each cluster and average silhouette score \n",
    "* Display Silhouette score plot\n",
    "* Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "silhouette_avg_score = silhouette_score(scaled_data_df[features], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "sample_silhouette_values = silhouette_samples(scaled_data_df[features], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "means_lst = []\n",
    "for label in range(3):\n",
    "    means_lst.append(sample_silhouette_values[labels == label].mean())\n",
    "print(means_lst)\n",
    "\n",
    "plt.plot(range(3), means_lst, color=\"r\")\n",
    "plt.plot(range(3), [silhouette_avg_score for i in range(3)],  color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As general guidelines, the plot can be interpreted by looking at:\n",
    "* *the thickness of the clusters (number of points)*;\n",
    "* check if any cluster has many negative values;\n",
    "* check the consistency of the silhouette widths within clusters;\n",
    "* the average value. Recall that in general, the following interpretation applies:\n",
    "    - \\> 0.7: Strong clustering structure\n",
    "    - 0.5 - 0.7: Reasonable clustering structure\n",
    "    - 0.25 - 0.5: Weak clustering structure\n",
    "    - < 0.25: No substantial clustering structure\n",
    "\n",
    "\n",
    "* Cluster Silhouette scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENT: TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Apply Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Apply Agglomerative clustering with different linkage options: complete, average, single. \n",
    "\n",
    "*Hint*: use [`sklearn.cluster.AgglomerativeClustering`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)\n",
    "* For each linkage, draw a dendrogram.\n",
    "* Calculate the silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "AggloCAvg = AgglomerativeClustering(linkage=\"average\").fit(data_cleaned_cluster[features])\n",
    "AggloCC = AgglomerativeClustering(linkage=\"complete\").fit(data_cleaned_cluster[features])\n",
    "AggloCS = AgglomerativeClustering(linkage=\"single\").fit(data_cleaned_cluster[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Plot dendrogram \n",
    "for method in [\"average\", \"complete\", \"single\"]:\n",
    "    linkage_matrix = linkage(scaled_data_df, method=method)\n",
    "    dendrogram(linkage_matrix, truncate_mode=\"level\", p=5, no_labels=True)\n",
    "    plt.title('Hierarchical Clustering Dendrogram ' + method) \n",
    "    plt.xlabel('Data point') \n",
    "    plt.ylabel('Distance') \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Apply DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Apply [sklearn.cluster.DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) algorithm\n",
    "* Identify the best values for `eps` and `min_sanples` by varying the values within a range and by using Silhouette coefficient\n",
    "* Apply DBSCAN with the best parameters found\n",
    "* Print number of clusters and noise points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Cluster Characterisation using Apriori algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we would like to describe the obtained cluster. To do so, let's use frequent pattern mining and in particular **Apriori algorithm**. \n",
    "\n",
    "**QUESTIONS**\n",
    "* First, convert numerical features to categorical (low, medium, high) based on quantiles. Add binary columns, e.g. `sepal length low`, `sepal length medium`, `sepal length high` depending on the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find association, we are going to use [mlxtend.frequent_patterns.apriori](https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent patterns\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "* Use apriori algorithm to find frequent patterns for each cluster\n",
    "* Then among these itemsets, find those that are not frequent for other clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
