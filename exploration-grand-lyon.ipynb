{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Data Mining project: Discover and describe areas of interest<br> and events from geo-located parsed_data</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0/ Import Dataset and Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Setting Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Actual environment location may have moved due to redirects, links or junctions.\n",
      "  Requested location: \"h:\\IF4\\fouilleD\\Data-Lyon-Mining_4IF\\dataMiningEnv\\Scripts\\python.exe\"\n",
      "  Actual location:    \"\\\\ps-home.insa-lyon.fr\\users\\home\\dlarrazmar\\IF4\\fouilleD\\Data-Lyon-Mining_4IF\\dataMiningEnv\\Scripts\\python.exe\"\n",
      "'source' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "! python -m venv dataMiningEnv\n",
    "#Activate windows\n",
    "#! dataMiningEnv\\Scripts\\activate.bat\n",
    "\n",
    "#Activate mac\n",
    "! source dataMiningEnv/bin/activate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"pip'\"\n",
      "WARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.26.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (1.26.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==2.1.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (2.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas==2.1.1) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas==2.1.1) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas==2.1.1) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from pandas==2.1.1) (1.26.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas==2.1.1) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn==1.5.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn==1.5.1) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn==1.5.1) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn==1.5.1) (1.26.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn==1.5.1) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib==3.8.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (3.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (3.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (1.26.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (4.55.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (11.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (6.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib==3.8.0) (0.12.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib==3.8.0) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib==3.8.0) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting folium==0.12.1\n",
      "  Downloading folium-0.12.1-py2.py3-none-any.whl (94 kB)\n",
      "Collecting jinja2>=2.9\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dlarrazmar\\appdata\\roaming\\python\\python39\\site-packages (from folium==0.12.1) (1.26.0)\n",
      "Collecting branca>=0.3.0\n",
      "  Downloading branca-0.8.1-py3-none-any.whl (26 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Installing collected packages: MarkupSafe, urllib3, jinja2, idna, charset-normalizer, certifi, requests, branca, folium\n",
      "Successfully installed MarkupSafe-3.0.2 branca-0.8.1 certifi-2024.12.14 charset-normalizer-3.4.1 folium-0.12.1 idna-3.10 jinja2-3.1.5 requests-2.32.3 urllib3-2.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# requires ipkernel\n",
    "! pip install --upgrade pip'\n",
    "# installation of required libraries and dependencies\n",
    "# numeric calculations\n",
    "! pip install numpy==1.26.0 \n",
    "# data frames \n",
    "! pip install pandas==2.1.1 \n",
    "# machine learning algorithms \n",
    "! pip install scikit-learn==1.5.1 \n",
    "#! pip install scipy==1.12.0\n",
    "# plotting \n",
    "#! pip install plotly==5.24.1 \n",
    "! pip install matplotlib==3.8.0 \n",
    "#! pip install seaborn==0.13.2 \n",
    "#! pip install plotly-express==0.4.1 \n",
    "#! pip install chart-studio==1.1.0 \n",
    "# web app library \n",
    "#! pip install streamlit==1.37.1 \n",
    "# association rules\n",
    "#! pip install mlxtend==0.23.3\n",
    "# Language processing\n",
    "#! pip install nltk\n",
    "#! python -m nltk.downloader popular # popular functions\n",
    "# Folium\n",
    "! pip install folium==0.12.1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###   Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.cluster as cl\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "#import nltk\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3 Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données avec low_memory=False pour éviter les avertissements\n",
    "DATA = pd.read_csv(\"data/flickr_data2.csv\", sep=\",\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1: Discovering areas of interests using clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Write something to describe this part of the report--"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Data clearing and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print details about parsing step:\n",
    "# -> Number of lines parsed - % of original data parsed\n",
    "def parse_conclusion(parsed_data):\n",
    "    l = len(parsed_data)\n",
    "    print(f\"<Lines parsed: {l} - {round(100*l/len(DATA),3)}% of original data>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1 : Nettoyage initial des colonnes\n",
    "# Supprimer les espaces supplémentaires dans les noms des colonnes\n",
    "parsed_data = DATA\n",
    "parsed_data.columns = parsed_data.columns.str.strip()\n",
    "\n",
    "# Convertir les colonnes temporelles en numériques\n",
    "# Liste des colonnes temporelles\n",
    "time_columns = [\n",
    "    'date_taken_minute', 'date_taken_hour', 'date_taken_day',\n",
    "    'date_taken_month', 'date_taken_year',\n",
    "    'date_upload_minute', 'date_upload_hour', 'date_upload_day',\n",
    "    'date_upload_month', 'date_upload_year'\n",
    "]\n",
    "\n",
    "# Convertir chaque colonne en int64, remplacer les erreurs par 0\n",
    "for col in time_columns:\n",
    "    parsed_data[col] = pd.to_numeric(data[col], errors='coerce').fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Lines parsed: 252143 - 60.0% of original data>\n"
     ]
    }
   ],
   "source": [
    "# Étape 2 : Suppression des doublons basés sur l'identifiant unique\n",
    "# Sauvegarder les doublons pour audit futur\n",
    "duplicate_data = parsed_data[parsed_data['id'].duplicated(keep='first')].sort_values(\"id\")\n",
    "duplicate_data.to_csv(\n",
    "    \"data/parsed_lines/duplicatedId.csv\", index=False\n",
    ")\n",
    "\n",
    "# Supprimer les doublons\n",
    "parsed_data = parsed_data[~parsed_data['id'].duplicated(keep='first')]\n",
    "\n",
    "parse_conclusion(duplicate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Lines parsed: 47 - 0.011% of original data>\n"
     ]
    }
   ],
   "source": [
    "# Étape 3 : Gestion des colonnes inutilisées ou corrompues\n",
    "# Identifier les colonnes inutiles\n",
    "unused_columns = [\"Unnamed: 16\", \"Unnamed: 17\", \"Unnamed: 18\", \n",
    "                  \"date_upload_minute\", \"date_upload_hour\", \"date_upload_day\", \n",
    "                  \"date_upload_month\", \"date_upload_year\"]\n",
    "\n",
    "# Sauvegarder les données corrompues\n",
    "corrupted_data = parsed_data[parsed_data[\"Unnamed: 16\"].notnull() | parsed_data[\"Unnamed: 17\"].notnull() | parsed_data[\"Unnamed: 18\"].notnull()]\n",
    "corrupted_data.to_csv(\n",
    "    \"data/parsed_lines/corrupted_data.csv\"\n",
    ", index=False)\n",
    "\n",
    "\n",
    "# Supprimer les colonnes inutilisées et les lignes corrompues\n",
    "parsed_data = parsed_data[~(parsed_data[\"Unnamed: 16\"].notnull() | parsed_data[\"Unnamed: 17\"].notnull() | parsed_data[\"Unnamed: 18\"].notnull())]\n",
    "parsed_data = parsed_data.drop(columns=unused_columns)\n",
    "\n",
    "parse_conclusion(corrupted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Lines parsed: 10502 - 2.499% of original data>\n"
     ]
    }
   ],
   "source": [
    "# Étape 4 : Nettoyage des coordonnées GPS\n",
    "# Définir les limites géographiques de Lyon\n",
    "lyon_lat_min, lyon_lat_max = 45.69, 45.85\n",
    "lyon_lon_min, lyon_lon_max = 4.78, 4.92\n",
    "\n",
    "# Sauvegarder les données not Lyonnaises ou non definies\n",
    "out_lyon_data = parsed_data[\n",
    "    ~((parsed_data['lat'] >= lyon_lat_min) & \n",
    "    (parsed_data['lat'] <= lyon_lat_max) &\n",
    "    (parsed_data['long'] >= lyon_lon_min) &\n",
    "    (parsed_data['long'] <= lyon_lon_max))\n",
    "]\n",
    "out_lyon_data.to_csv(\n",
    "    \"data/parsed_lines/out_lyon.csv\"\n",
    ", index=False)\n",
    "\n",
    "# Filtrer les données pour garder uniquement les points dans Lyon\n",
    "parsed_data = parsed_data[\n",
    "    (parsed_data['lat'] >= lyon_lat_min) & \n",
    "    (parsed_data['lat'] <= lyon_lat_max) &\n",
    "    (parsed_data['long'] >= lyon_lon_min) &\n",
    "    (parsed_data['long'] <= lyon_lon_max)\n",
    "]\n",
    "\n",
    "parse_conclusion(out_lyon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Lines parsed: 0 - 0.0% of original data>\n"
     ]
    }
   ],
   "source": [
    "# Étape 5 : Gestion des valeurs manquantes\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "#parsed_data = parsed_data.dropna(subset=['id', 'user', 'lat', 'long', 'tags', 'title', 'date_taken_minute', 'date_taken_hour', 'date_taken_day', 'date_taken_month', 'date_taken_year'])\n",
    "\n",
    "# Sauvegarder les lignes à données manquantes\n",
    "val_manquante_data = parsed_data[parsed_data.drop(columns=['tags','title']).isna().any(axis = 1)]\n",
    "val_manquante_data.to_csv(\n",
    "    \"data/parsed_lines/NaNs.csv\"\n",
    ", index=False)\n",
    "\n",
    "# Remplir les valeurs manquantes pour les colonnes textuelles par des chaînes vides\n",
    "parsed_data['tags'] = parsed_data['tags'].fillna('')\n",
    "parsed_data['title'] = parsed_data['title'].fillna('')\n",
    "\n",
    "parse_conclusion(val_manquante_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Lines parsed: 2028 - 0.483% of original data>\n"
     ]
    }
   ],
   "source": [
    "# Étape 6 : Filtrage des dates incohérentes\n",
    "\n",
    "min_year = 2009\n",
    "\n",
    "# Sauvegarder les données ayant des date non correcte\n",
    "uncorrect_date_data = parsed_data[\n",
    "    ~((parsed_data['date_taken_year'] >= min_year) & (parsed_data['date_taken_year'] <= 2025) &\n",
    "    (parsed_data['date_taken_month'] >= 1) & (parsed_data['date_taken_month'] <= 12) &\n",
    "    (parsed_data['date_taken_day'] >= 1) & (parsed_data['date_taken_day'] <= 31) &\n",
    "    (parsed_data['date_taken_hour'] >= 0) & (parsed_data['date_taken_hour'] <= 23) &\n",
    "    (parsed_data['date_taken_minute'] >= 0) & (parsed_data['date_taken_minute'] <= 59))\n",
    "]\n",
    "uncorrect_date_data.to_csv(\n",
    "    \"data/parsed_lines/uncorrect_date.csv\"\n",
    ", index=False)\n",
    "\n",
    "# Garder uniquement les dates raisonnables (entre 2009 et 2025)\n",
    "parsed_data = parsed_data[\n",
    "    (parsed_data['date_taken_year'] >= min_year) & (parsed_data['date_taken_year'] <= 2025) &\n",
    "    (parsed_data['date_taken_month'] >= 1) & (parsed_data['date_taken_month'] <= 12) &\n",
    "    (parsed_data['date_taken_day'] >= 1) & (parsed_data['date_taken_day'] <= 31) &\n",
    "    (parsed_data['date_taken_hour'] >= 0) & (parsed_data['date_taken_hour'] <= 23) &\n",
    "    (parsed_data['date_taken_minute'] >= 0) & (parsed_data['date_taken_minute'] <= 59) \n",
    "]\n",
    "\n",
    "parse_conclusion(uncorrect_date_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 7 : Nettoyage/Standarisation des colonnes textuelles\n",
    "# Fonction pour nettoyer le texte\n",
    "def clean_text(text):\n",
    "    # Supprimer les caractères spéciaux et passer en minuscules\n",
    "    return re.sub(r'[^a-zA-Z0-9, ]', '', text).lower()\n",
    "\n",
    "# Appliquer le nettoyage sur les colonnes textuelles\n",
    "parsed_data['tags'] = parsed_data['tags'].apply(clean_text)\n",
    "parsed_data['title'] = parsed_data['title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données nettoyées :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4395181099</td>\n",
       "      <td>30624617@N03</td>\n",
       "      <td>45.754858</td>\n",
       "      <td>4.821710</td>\n",
       "      <td>chair,lyon,rhne,chaise,rhnealpes</td>\n",
       "      <td>chaises avec vue</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4394748717</td>\n",
       "      <td>35853470@N00</td>\n",
       "      <td>45.753270</td>\n",
       "      <td>4.862953</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394694699</td>\n",
       "      <td>11817998@N05</td>\n",
       "      <td>45.760655</td>\n",
       "      <td>4.846564</td>\n",
       "      <td>365,iphone</td>\n",
       "      <td>59365  r46 v103 b163</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4394803790</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>20100129 toiou avott lyon</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4394803554</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>lyon,nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>20100128 toiou avott lyon</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          user        lat      long  \\\n",
       "0  4395181099  30624617@N03  45.754858  4.821710   \n",
       "1  4394748717  35853470@N00  45.753270  4.862953   \n",
       "2  4394694699  11817998@N05  45.760655  4.846564   \n",
       "3  4394803790  11545749@N06  45.784000  4.874072   \n",
       "4  4394803554  11545749@N06  45.784000  4.874072   \n",
       "\n",
       "                                                tags  \\\n",
       "0                   chair,lyon,rhne,chaise,rhnealpes   \n",
       "1                                                      \n",
       "2                                         365,iphone   \n",
       "3       nin,nineinchnails,gift,screening,toiou,avott   \n",
       "4  lyon,nin,nineinchnails,gift,screening,toiou,avott   \n",
       "\n",
       "                       title  date_taken_minute  date_taken_hour  \\\n",
       "0           chaises avec vue                 11               15   \n",
       "1                                            51               17   \n",
       "2       59365  r46 v103 b163                 29               17   \n",
       "3  20100129 toiou avott lyon                 15               20   \n",
       "4  20100128 toiou avott lyon                 10               20   \n",
       "\n",
       "   date_taken_day  date_taken_month  date_taken_year  \n",
       "0              28                 2             2010  \n",
       "1              28                 2             2010  \n",
       "2              28                 2             2010  \n",
       "3              28                 1             2010  \n",
       "4              28                 1             2010  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résumé final des données nettoyées\n",
    "print(\"Données nettoyées :\")\n",
    "\n",
    "# Sauvegarder les données nettoyées pour les prochaines étapes\n",
    "parsed_data.to_csv(\"data/cleaned_flickr_data.csv\", index=False)\n",
    "\n",
    "parsed_data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II/ Visualize geolocated points on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the center of Lyon\n",
    "lyon_lat, lyon_lon = 45.75, 4.85  # Approximate coordinates for Lyon, France\n",
    "\n",
    "# Create a Folium map\n",
    "map_lyon = folium.Map(location=[lyon_lat, lyon_lon], zoom_start=12)\n",
    "\n",
    "# Create a marker cluster\n",
    "marker_cluster = MarkerCluster().add_to(map_lyon)\n",
    "\n",
    "# Add points from the dataset\n",
    "for _, row in parsed_data.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['lat'], row['long']],  # Replace with 'lat' and 'long' if necessary\n",
    "        popup=f\"Tags: {row['tags']}, Title: {row['title']}\",  # Optional popup information\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Display the map\n",
    "map_lyon\n",
    "\n",
    "# Optional: Save the map as an HTML file\n",
    "map_lyon.save(\"lyon_map_unclustered.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III/ Clustering data by proximity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Km_clustered_data = parsed_data\n",
    "# number of clusters \n",
    "k = 3\n",
    "# create a model\n",
    "kmeans = cl.KMeans(n_clusters=k, init='k-means++')\n",
    "# fit scaled data\n",
    "kmeans.fit(Km_clustered_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataMiningEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
